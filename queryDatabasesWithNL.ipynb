{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Column, Table, String, MetaData\n",
    "\n",
    "# --- Define the directory path ---\n",
    "DB_DIR = \"databases\" \n",
    "DB_FILE = f'sqlite:///{DB_DIR}/cats.db'\n",
    "\n",
    "# --- 1. Ensure the directory exists ---\n",
    "if not os.path.exists(DB_DIR):\n",
    "    # This creates the 'databases' folder if it doesn't exist\n",
    "    os.makedirs(DB_DIR) \n",
    "\n",
    "# --- 2. Create the engine now that the path is guaranteed to exist ---\n",
    "metadata_obj = MetaData()\n",
    "engine = create_engine(DB_FILE, future=True)\n",
    "\n",
    "cat_breeds_table = Table(\n",
    "    \"cat_breeds\",\n",
    "    metadata_obj,\n",
    "    Column(\"name\", String(16), primary_key=True),\n",
    "    Column(\"origin\", String(16), nullable=False),\n",
    "    Column(\"temperament\", String(16), nullable=False),\n",
    "    Column(\"size\", String(16), nullable=False),\n",
    "    Column(\"social_behavior\", String(16), nullable=False),\n",
    ")\n",
    "\n",
    "metadata_obj.create_all(engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import insert\n",
    "\n",
    "breeds_data = [\n",
    "    {\n",
    "        'name': 'Savannah',\n",
    "        'origin': 'USA',\n",
    "        'temperament': 'high energy',\n",
    "        'size': 'Large',\n",
    "        'social_behavior': 'sociable'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Ragdoll',\n",
    "        'origin': 'USA',\n",
    "        'temperament': 'gentle',\n",
    "        'size': 'Large',\n",
    "        'social_behavior': 'sociable'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Maine Coon',\n",
    "        'origin': 'USA (Maine)',\n",
    "        'temperament': 'friendly',\n",
    "        'size': 'Very Large',\n",
    "        'social_behavior': 'sociable'\n",
    "    }\n",
    "]\n",
    "for breed in breeds_data:\n",
    "    stmt = insert(cat_breeds_table).values(**breed)\n",
    "    with engine.connect() as connection:\n",
    "        cursor = connection.execute(stmt)\n",
    "        connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Savannah', 'USA', 'high energy', 'Large', 'sociable'), ('Ragdoll', 'USA', 'gentle', 'Large', 'sociable'), ('Maine Coon', 'USA (Maine)', 'friendly', 'Very Large', 'sociable')]\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as connection:\n",
    "    result = connection.exec_driver_sql(\"SELECT * FROM cat_breeds\")\n",
    "    print(result.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SQLDatabase\n",
    "sql_database = SQLDatabase(engine, include_tables=[\"cat_breeds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.settings import Settings\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4\", temperature=0, verbose=True)\n",
    "Settings.llm = llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (0.14.4)\n",
      "Requirement already satisfied: llama-index-cli<0.6,>=0.5.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index) (0.5.3)\n",
      "Requirement already satisfied: llama-index-core<0.15.0,>=0.14.4 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index) (0.14.4)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.6,>=0.5.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index) (0.5.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index) (0.9.4)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.7,>=0.6.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index) (0.6.1)\n",
      "Requirement already satisfied: llama-index-readers-file<0.6,>=0.5.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index) (0.5.4)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index) (0.5.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index) (3.9.2)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (3.12.15)\n",
      "Requirement already satisfied: aiosqlite in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (2025.9.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<3,>=2 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (2.6.0)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (3.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (2.3.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (11.3.0)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (4.4.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (2.11.10)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.4->llama-index) (2.0.43)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (0.11.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (4.15.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-core<0.15.0,>=0.14.4->llama-index) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.4->llama-index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.4->llama-index) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.4->llama-index) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.4->llama-index) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.4->llama-index) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.4->llama-index) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.4->llama-index) (1.20.1)\n",
      "Requirement already satisfied: griffe in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.4->llama-index) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.4->llama-index) (3.1.6)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.109.1)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.14.2)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
      "Requirement already satisfied: pandas<2.3.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.2.3)\n",
      "Requirement already satisfied: pypdf<7,>=5.1.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (6.1.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.8)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-workflows<3,>=2->llama-index-core<0.15.0,>=0.14.4->llama-index) (0.4.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (0.11.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from httpx->llama-index-core<0.15.0,>=0.14.4->llama-index) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from httpx->llama-index-core<0.15.0,>=0.14.4->llama-index) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.15.0,>=0.14.4->llama-index) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.4->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.4->llama-index) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.4->llama-index) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.15.0,>=0.14.4->llama-index) (0.4.6)\n",
      "Requirement already satisfied: llama-cloud==0.1.35 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.35)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.54 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
      "Requirement already satisfied: click<9,>=8.1.7 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (8.3.0)\n",
      "Requirement already satisfied: python-dotenv<2,>=1.0.1 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from nltk>3.8.1->llama-index) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from nltk>3.8.1->llama-index) (2025.9.18)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.4->llama-index) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.4->llama-index) (2.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.4->llama-index) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.4->llama-index) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from dataclasses-json->llama-index-core<0.15.0,>=0.14.4->llama-index) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15.0,>=0.14.4->llama-index) (25.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\win 11\\desktop\\llamaindexscripts\\env\\lib\\site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.4->llama-index) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.core.query_engine.sql'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mpip\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33minstall llama-index\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquery_engine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NLSQLTableQueryEngine\n\u001b[32m      5\u001b[39m query_engine = NLSQLTableQueryEngine(\n\u001b[32m      6\u001b[39m     sql_database,\n\u001b[32m      7\u001b[39m     context_query_kwargs={\u001b[33m\"\u001b[39m\u001b[33mcat_breeds\u001b[39m\u001b[33m\"\u001b[39m: (\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     )}\n\u001b[32m     12\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'llama_index.core.query_engine.sql'"
     ]
    }
   ],
   "source": [
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "\n",
    "query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database,\n",
    "    context_query_kwargs={\"cat_breeds\": (\n",
    "        \"The only columns available are: name,origin,temperament,size,social_behavior. Do not use other columns and foreign keys. \\n\"\n",
    "        \"Do not attempt to run a query if the column is not among available columns.\\n\"\n",
    "        \"Do not use unexistant colums in a WHERE part of the query. \\n\"\n",
    "    )}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.log = \"debug\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.struct_store.sql_query:> Table desc str: Table 'cat_breeds' has columns: name (VARCHAR(16)), origin (VARCHAR(16)), temperament (VARCHAR(16)), size (VARCHAR(16)), social_behavior (VARCHAR(16)), and foreign keys: . The table description is: The only columns available are: name,origin,temperament,size,social_behavior. Do not use other columns and foreign keys. \n",
      "Do not attempt to run a query if the column is not among available columns.\n",
      "Do not use unexistant colums in a WHERE part of the query. \n",
      "\n",
      "> Table desc str: Table 'cat_breeds' has columns: name (VARCHAR(16)), origin (VARCHAR(16)), temperament (VARCHAR(16)), size (VARCHAR(16)), social_behavior (VARCHAR(16)), and foreign keys: . The table description is: The only columns available are: name,origin,temperament,size,social_behavior. Do not use other columns and foreign keys. \n",
      "Do not attempt to run a query if the column is not among available columns.\n",
      "Do not use unexistant colums in a WHERE part of the query. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Given an input question, first create a syntactically correct sqlite query to run, then look at the results of the query and return the answer. You can order the results by a relevant column to return the most interesting examples in the database.\\\\nNever query for all the columns from a specific table, only ask for a few relevant columns given the question.\\\\nPay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Pay attention to which column is in which table. Also, qualify column names with the table name when needed.\\\\nUse the following format:\\\\nQuestion: Question here\\\\nSQLQuery: SQL Query to run\\\\nSQLResult: Result of the SQLQuery\\\\nAnswer: Final answer here\\\\nOnly use the tables listed below.\\\\nTable \\'cat_breeds\\' has columns: name (VARCHAR(16)), origin (VARCHAR(16)), temperament (VARCHAR(16)), size (VARCHAR(16)), social_behavior (VARCHAR(16)), and foreign keys: . The table description is: The only columns available are: name,origin,temperament,size,social_behavior. Do not use other columns and foreign keys. \\\\nDo not attempt to run a query if the column is not among available columns.\\\\nDo not use unexistant colums in a WHERE part of the query. \\\\n\\\\nQuestion: What kind of a temperament does a Ragdoll cat have?\\\\nSQLQuery: \"}], \"stream\": false, \"model\": \"gpt-3.5-turbo\", \"temperature\": 0.1, \"max_tokens\": null}' message='Post details'\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2358 request_id=5eae84607f034e235a0527c13fb49491 response_code=200\n",
      "body='{\\n  \"id\": \"chatcmpl-7yfj7aqh4L9S6z31IhCQN6PDye6Dt\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1694694433,\\n  \"model\": \"gpt-3.5-turbo-0613\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": \"SELECT temperament\\\\nFROM cat_breeds\\\\nWHERE name = \\'Ragdoll\\'\\\\nSQLResult: The result of the query would depend on the data in the database.\\\\nAnswer: The temperament of a Ragdoll cat is [temperament].\"\\n      },\\n      \"finish_reason\": \"stop\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 299,\\n    \"completion_tokens\": 49,\\n    \"total_tokens\": 348\\n  }\\n}\\n' headers='{\\'Date\\': \\'Thu, 14 Sep 2023 12:27:16 GMT\\', \\'Content-Type\\': \\'application/json\\', \\'Transfer-Encoding\\': \\'chunked\\', \\'Connection\\': \\'keep-alive\\', \\'access-control-allow-origin\\': \\'*\\', \\'Cache-Control\\': \\'no-cache, must-revalidate\\', \\'openai-model\\': \\'gpt-3.5-turbo-0613\\', \\'openai-organization\\': \\'user-k8oyxwpy2ln43xyfwaaakcre\\', \\'openai-processing-ms\\': \\'2358\\', \\'openai-version\\': \\'2020-10-01\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'x-ratelimit-limit-requests\\': \\'3500\\', \\'x-ratelimit-limit-tokens\\': \\'90000\\', \\'x-ratelimit-remaining-requests\\': \\'3499\\', \\'x-ratelimit-remaining-tokens\\': \\'89655\\', \\'x-ratelimit-reset-requests\\': \\'17ms\\', \\'x-ratelimit-reset-tokens\\': \\'230ms\\', \\'x-request-id\\': \\'5eae84607f034e235a0527c13fb49491\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'80689f734cb0b37a-PRG\\', \\'Content-Encoding\\': \\'gzip\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n",
      "message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "api_version=None data='{\"messages\": [{\"role\": \"user\", \"content\": \"Given an input question, synthesize a response from the query results.\\\\nQuery: What kind of a temperament does a Ragdoll cat have?\\\\nSQL: SELECT temperament\\\\nFROM cat_breeds\\\\nWHERE name = \\'Ragdoll\\'\\\\nSQL Response: [(\\'gentle\\',)]\\\\nResponse: \"}], \"stream\": false, \"model\": \"gpt-3.5-turbo\", \"temperature\": 0.1, \"max_tokens\": null}' message='Post details'\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=816 request_id=7e393c31d76f1873b082183e91984c06 response_code=200\n",
      "body='{\\n  \"id\": \"chatcmpl-7yfjAIvHjNSwv7P8MvAKPNzKmCmJw\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1694694436,\\n  \"model\": \"gpt-3.5-turbo-0613\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": \"The Ragdoll cat breed is known for having a gentle temperament.\"\\n      },\\n      \"finish_reason\": \"stop\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 65,\\n    \"completion_tokens\": 13,\\n    \"total_tokens\": 78\\n  }\\n}\\n' headers='{\\'Date\\': \\'Thu, 14 Sep 2023 12:27:17 GMT\\', \\'Content-Type\\': \\'application/json\\', \\'Transfer-Encoding\\': \\'chunked\\', \\'Connection\\': \\'keep-alive\\', \\'access-control-allow-origin\\': \\'*\\', \\'Cache-Control\\': \\'no-cache, must-revalidate\\', \\'openai-model\\': \\'gpt-3.5-turbo-0613\\', \\'openai-organization\\': \\'user-k8oyxwpy2ln43xyfwaaakcre\\', \\'openai-processing-ms\\': \\'816\\', \\'openai-version\\': \\'2020-10-01\\', \\'strict-transport-security\\': \\'max-age=15724800; includeSubDomains\\', \\'x-ratelimit-limit-requests\\': \\'3500\\', \\'x-ratelimit-limit-tokens\\': \\'90000\\', \\'x-ratelimit-remaining-requests\\': \\'3499\\', \\'x-ratelimit-remaining-tokens\\': \\'89925\\', \\'x-ratelimit-reset-requests\\': \\'17ms\\', \\'x-ratelimit-reset-tokens\\': \\'50ms\\', \\'x-request-id\\': \\'7e393c31d76f1873b082183e91984c06\\', \\'CF-Cache-Status\\': \\'DYNAMIC\\', \\'Server\\': \\'cloudflare\\', \\'CF-RAY\\': \\'80689f848c88b37a-PRG\\', \\'Content-Encoding\\': \\'gzip\\', \\'alt-svc\\': \\'h3=\":443\"; ma=86400\\'}' message='API response body'\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What kind of a temperament does a Ragdoll cat have?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ragdoll cat breed is known for having a gentle temperament.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': [('gentle',)],\n",
       " 'sql_query': \"SELECT temperament\\nFROM cat_breeds\\nWHERE name = 'Ragdoll'\"}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
